{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMEaSJ9YKb5UETzInng4mVy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","\n","# Load the ovarian cancer dataset (replace 'OC.csv' with your file path)\n","dataset = pd.read_csv('OC.csv')\n","\n","# Assuming the 'M/Z' and 'Intensity' columns are features and the last column is the target\n","X = dataset[['M/Z', 'Intensity']].values\n","y = dataset.iloc[:, -1].values\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define the genetic algorithm functions\n","def initialize_population(population_size, n_features):\n","    return np.random.randint(2, size=(population_size, n_features))\n","\n","def fitness(population, X_train, X_test, y_train, y_test):\n","    errors = []\n","    for chromosome in population:\n","        selected_features = [bool(bit) for bit in chromosome]\n","\n","        # Ensure at least one feature is selected\n","        if not any(selected_features):\n","            selected_features[np.random.randint(len(selected_features))] = True\n","\n","        X_train_selected = X_train[:, selected_features]\n","        X_test_selected = X_test[:, selected_features]\n","\n","        # Train a regressor (Random Forest Regressor in this case)\n","        clf = RandomForestRegressor(n_estimators=100, random_state=42)\n","        clf.fit(X_train_selected, y_train)\n","\n","        # Evaluate the model\n","        y_pred = clf.predict(X_test_selected)\n","        error = mean_squared_error(y_test, y_pred)\n","        errors.append(error)\n","\n","    return np.array(errors)\n","\n","# Genetic Algorithm Parameters\n","population_size = 10\n","n_features = X_train.shape[1]\n","n_generations = 20\n","mutation_rate = 0.1\n","\n","# Initialize population\n","population = initialize_population(population_size, n_features)\n","\n","# Evolutionary loop\n","for generation in range(n_generations):\n","    # Evaluate fitness\n","    fitness_scores = fitness(population, X_train, X_test, y_train, y_test)\n","\n","    # Select parents\n","    parents = select_parents(population, fitness_scores)\n","\n","    # Create offspring through crossover\n","    offspring = [crossover(parents[0], parents[1]) for _ in range(population_size - 2)]\n","\n","    # Mutate offspring\n","    offspring = [mutate(child, mutation_rate) for child in offspring]\n","\n","    # Create next generation\n","    population[2:] = offspring\n","\n","# Select the best individual from the final population\n","best_individual = population[np.argmin(fitness(population, X_train, X_test, y_train, y_test))]\n","\n","# Train the final model using the best features\n","selected_features = [bool(bit) for bit in best_individual]\n","X_train_final = X_train[:, selected_features]\n","X_test_final = X_test[:, selected_features]\n","\n","final_clf = RandomForestRegressor(n_estimators=100, random_state=42)\n","final_clf.fit(X_train_final, y_train)\n","\n","# Evaluate the final model\n","y_pred_final = final_clf.predict(X_test_final)\n","final_error = mean_squared_error(y_test, y_pred_final)\n","\n","print(f\"Final Model Mean Squared Error: {final_error}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3g-jYig2r9h4","executionInfo":{"status":"ok","timestamp":1709644690955,"user_tz":-330,"elapsed":467264,"user":{"displayName":"ANANYA MADHAVAN (RA2111047010116)","userId":"10888489958497100076"}},"outputId":"765cd03a-edc4-4fe9-c9be-91e375a28447"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Final Model Mean Squared Error: 0.000839805109560141\n"]}]}]}